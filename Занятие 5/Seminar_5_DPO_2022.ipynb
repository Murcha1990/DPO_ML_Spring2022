{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решение задач классификации.\n",
    "\n",
    "* Порешаем теоретические задачи на логистическую регрессию.\n",
    "* Научимся решать линейные и нелинейные задачи классификации с логистической регрессии.\n",
    "* Разберём, как подбирать гиперпараметры моделей по сетке.\n",
    "* Потренируемся применять пайплайны."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Решение теоретических задач\n",
    "\n",
    "**Задание 1**. Рассмотрим логистическую регрессию в задаче предсказания целевой переменной по двум признакам: $a(x)=\\sigma(w_0+w_1\\cdot x_1 +w_2\\cdot x_2)$. \n",
    "\n",
    "После оценки качества алгоритма по кросс-валидации выяснилось, что модель переобучилась. Какие из нижеперечисленных подходов корректно описаны и их можно предпринять для уменьшения переобучения?\n",
    "\n",
    "1) Уберём константный коэффициент $w_0$, так как он увеличивает сложность модели и при этом не влияет на обобщающую способность модели\n",
    "\n",
    "2) Добавим к модели регуляризатор $w_0^2 +w_1^2 +w_2^2$, так как l2-регуляризация может уменьшить переобучение\n",
    "\n",
    "3) Добавим к модели регуляризатор вида $|w_1|+|w_2|$, так как l1-регуляризация может уменьшить переобучение\n",
    "\n",
    "4) Добавим к модели регуляризатор вида $[w_1\\neq 0]+[w_2\\neq 0]$, так как l0-регуляризация может уменьшить переобучение (здесь [x] = 1, если выражение x верно, а иначе 0)\n",
    "\n",
    "5) Добавим полиномиальных признаков второй степени, чтобы увеличить обобщающую способность модели\n",
    "\n",
    "\n",
    "**Задание 2**. ![Задание 5](задача2.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Задача 1: многоклассовая классификация цветков ириса.\n",
    "\n",
    "![Ирисы](irises.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведите на экран все различные значения целевой переменной, а также распределение классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для решения этой задачи будем использовать **линейную модель - логистическую регрессию**.\n",
    "\n",
    "Разбейте данные на train и test (test - 20% от всех данных)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите логистическую регрессию на train и выведем качество (accuracy) на train и на test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрите на качество алгоритма на кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили очень высокую точность модели.\n",
    "\n",
    "Посмотрим, можно ли улучшить качество модели **подбором её гиперпараметров**. Логистическая регрессия имеет гиперпараметр C - подберём его. \n",
    "\n",
    "* Подбор гиперпараметров традиционно осуществляется \"по сетке\" с помощью функции ***GridSearchCV***. \n",
    "\n",
    "GridSearchCV - это класс, который ищет с помощью кросс-валидации (CV) по сетке наилучшую комбинацию искомых параметров. \n",
    "\n",
    "*За что отвечает гиперпараметр С?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'C': np.arange(0.1,1.1,0.1)}\n",
    "grid = GridSearchCV(model, params)\n",
    "\n",
    "grid.fit(X, y)\n",
    "\n",
    "print('best score:', grid.best_score_)\n",
    "print('best params:', grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача уже решена очень хорошо. На этом можно ставить точку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 2: задача XOR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![How it works](XOR.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим данные для задачи XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(0)\n",
    "X = rng.randn(200, 2)\n",
    "y = np.logical_xor(X[:, 0] > 0, X[:, 1] > 0)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], s=30, c=y, cmap=plt.cm.Paired);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем использовать функцию, которая рисует разделяющую границу, проведенную классификатором."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boundary(clf, X, y, plot_title):\n",
    "    xx, yy = np.meshgrid(np.linspace(-3, 3, 50), np.linspace(-3, 3, 50))\n",
    "    clf.fit(X, y)\n",
    "    # plot the decision function for each datapoint on the grid\n",
    "    Z = clf.predict_proba(np.vstack((xx.ravel(), yy.ravel())).T)[:, 1]\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    image = plt.imshow(Z, interpolation='nearest',\n",
    "                       extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "                       aspect='auto', origin='lower', cmap=plt.cm.PuOr_r)\n",
    "    contours = plt.contour(xx, yy, Z, levels=[0], linewidths=2,\n",
    "                               linetypes='--')\n",
    "    plt.scatter(X[:, 0], X[:, 1], s=30, c=y, cmap=plt.cm.Paired)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.xlabel(r'$x_1$')\n",
    "    plt.ylabel(r'$x_2$')\n",
    "    plt.axis([-3, 3, -3, 3])\n",
    "    plt.colorbar(image)\n",
    "    plt.title(plot_title, fontsize=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boundary(LogisticRegression(solver='lbfgs'), X, y, \"Logistic Regression, XOR problem\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим качество полученной классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(model, X, y, cv=3, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что задача решена плохо. Попробуем подобрать гиперпараметр C в логистической регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'C': np.arange(0.1,1.1,0.1)}\n",
    "grid = GridSearchCV(model, params)\n",
    "\n",
    "grid.fit(X, y)\n",
    "\n",
    "print('best score:', grid.best_score_)\n",
    "print('best params:', grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что подбор гиперпараметра не помог, и задача всё ещё решена плохо. Получается, что линейный классификатор (а именно, логистическая регрессия), плохо решает эту задачу. Это и понятно, ведь *данные нелинейные*.\n",
    "\n",
    "Попробуем добавить в качестве признаков полиномиальные признаки степени 2.\n",
    "\n",
    "Теперь у нас будут признаки не только $(1, x_1, x_2)$, но и $1, x_1, x_2, x_1^2, x_1x_2, x_2^2$.\n",
    "\n",
    "Будем использовать удобную функцию *Pipeline* для описания модели.\n",
    "\n",
    "***Pipeline***.\n",
    "* С помощью Pipeline можно соорудить модель, в которой кроме непосредственно применения некоторого алгоритма происходит какая-либо обработка данных.\n",
    "* В нашей задаче необходимо сначала извлечь полиномиальные признаки, а затем обучить логистическую регрессию. Эти два действия можно осуществить внутри одной \"комбинированной\" модели с помощью Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "logit_pipe = Pipeline([('poly', PolynomialFeatures(degree=2)),\n",
    "                       ('logit', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите оптимальное значение гиперпараметра C с помощью GridSearchCV и оцените качество модели (на кросс-валидации)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boundary(logit_pipe, X, y,\n",
    "              \"Logistic Regression + quadratic features. XOR problem\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Таким образом, при добавлении новых нелинейных признаков с помощью линейного классификатора можно решить линейно неразделимую задачу.**\n",
    "\n",
    "* **Другой способ решить такую задачу - сразу использовать нелинейные классификаторы (попробуем на следующих семинарах).** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
